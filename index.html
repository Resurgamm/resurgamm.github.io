---
layout: page
title: Boyi Li
subtitle: B.Eng. in Computer Engineering @ ZJU - UIUC Institute
use-site-title: false
---

<head>
	<style>
		a { text-decoration : none; }
		a:hover { text-decoration : underline; }
		a, a:visited { color : #b5194f; }
	</style>
	<script src="https://kit.fontawesome.com/5bef57b3e9.js" crossorigin="anonymous"></script>
</head>

<h1 id="-about-me">ðŸ—¨ About Me</h1>
<br>
Hi, I'm Boyi Li. I am pursuing my B.Eng. degree in Computer Engineering at the ZJU-UIUC Institute. 
<br>
I'm now a research intern in <a href="https://rehg.org/">Rehg Lab</a> in UIUC. I'm also very fortunate to be a research assistant in <a href="https://cvnext.github.io/">CVNext Lab</a> advised by Prof. <a href="https://person.zju.edu.cn/en/gaoangwang/">Gaoang Wang</a>. 
<br>
My research interests include embodied AI, multimodal large language models, multi-agent planning and multi-modality learning.

<br>
<br>
<hr style="height:2px;border-width:0;color:gray;background-color:gray">
<b><i class="fa-regular fa-note-sticky" style="font-size:24px"></i> Selected Publications:</b>
<p><font color="grey" size="3">
* Equal contribution. â™¡ Project lead. âœ‰ corresponding / co-corresponding author.
<br>
Also see <a href="https://resurgamm.github.io/publications" target="_blank">Publications Page</a> and <a href="https://scholar.google.com/citations?user=UDWzqY0AAAAJ&hl=en" target="_blank">Google Scholar</a>.
</font></p>

<ul>
	<li>
		<p style="font-size:16px"> 
			<strong>
			See and think: Embodied agent in virtual environment
			</strong>
			<br>
			Zhonghan Zhao*,  Wenhao Chai*â™¡, Xuan Wang*, <b>Boyi Li</b>, Shengyu Hao, Shidong Cao, Tian Ye, Jenq-Neng Hwang, Gaoang Wangâœ‰
			<a href="https://arxiv.org/abs/2311.15209">[Paper]</a>
			<a href="https://github.com/rese1f/STEVE">[Code]</a>
			<a href="https://rese1f.github.io/STEVE/">[Demo]</a>
			<br>
			<font color="grey" size="2">
			A comprehensive and visionary embodied agent in the Minecraft virtual environment comprises three key components: vision perception, language instruction, and code action.
			</font>
	  	</p>
	</li>
	<li>
		<p style="font-size:16px"> 
			<strong>
			Adaptive Graph Pruning for Multi-Agent Communication
			</strong>
			<br>
			<b>Boyi Li*</b>, Zhonghan Zhao*â™¡, Der-Horng Leeâœ‰, Gaoang Wangâœ‰
			<a href="https://arxiv.org/abs/2506.02951">[Paper]</a>
			<a href="https://github.com/Resurgamm/AGP">[Code]</a>
			<a href="https://resurgamm.github.io/AGP/">[Demo]</a>
			<br>
			<font color="grey" size="2">
			A novel task-adaptive multi-agent collaboration framework that jointly optimizes agent quantity (hard-pruning) and communication topology (soft-pruning), dynamically constructing optimized communication topologies tailored specifically to individual tasks. 
			</font>
	  	</p>
	</li><br>
	
</ul>

<hr style="height:2px;border-width:0;color:gray;background-color:gray">
<b><i class="fa fa-newspaper-o" aria-hidden="true" style="font-size:24px"></i> News:</b><br><br>

<ul>		
	<li><i>July 2024:</i> <i class="fa-regular fa-note-sticky" style="font-size:20px"></i> Our paper <i>See and think: Embodied agent in virtual environment</i> is accepted by ECCV-2024.
	</li><be>
</ul>

<ul>		
	<li><i>July 2025:</i> <i class="fa-regular fa-note-sticky" style="font-size:20px"></i> Our paper <i>Adaptive Graph Pruning for Multi-Agent Communication</i> is accepted by ECAI-2025.
	</li><be>
</ul>
